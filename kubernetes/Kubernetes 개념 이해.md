# Kubernetes 개념 이해

[TOC]



## 1. 개요

### 1. 쿠버네티스란 무엇인가?

![배포 혁명](https://d33wubrfki0l68.cloudfront.net/26a177ede4d7b032362289c6fccd448fc4a91174/eb693/images/docs/container_evolution.svg)

* 배포 개념의 변화
  1. 단일 물리 서버에서 애플리케이션 배포
  2. 단일 물리 서버의 CPU에서 여러 가상 시스템을 실행하여 애플리케이션 배포
  3. VM의 격리 속성을 완화시킨 컨테이너에 애플리케이션을 배포



* 컨테이너의 장점

  * VM 보다 컨테이너 이미지 생성이 보다 쉽고 효율적

  * 컨테이너 이미지 빌드가 안정적이고 주기적

  * 이미지의 불변적 특성 때문에 롤백이 빠르고 쉬움

  * 배포 시점이 아닌 빌드, 릴리즈 시점에 이미지를 빌드하므로, 애플리케이션이 인프라 스트럭쳐에서 분리됨

  * OS 수준의 정보와 메트릭 뿐만 아니라, 애플리케이션의 헬스와 시그널을 확인할 수 있음

  * 환경에 대해 일관성 있고, 이식성이 좋음

  * 실제 OS 리소스를 이용해 애플리케이션을 실행

  * 마이크로 서비스 => 작은 단위의 애플리케이션을 동적으로 배포 및 관리할 수 있음

    

* 컨테이너를 통한 애플리케이션 배포에 쿠버네티스를 어떻게 활용할 수 있는가?

  * 쿠버네티스는 분산 시스템을 탄력적으로 실행하기 위한 프레임워크를 제공
  * 서비스 디스커버리와 로드 밸런싱
    * DNS나 자체 IP를 이용하여 컨테이너를 노출

  * 스토리지 오케스트레이션
    * 로컬 저장소, 공용 클라우드 등 원하는 저장소 시스템을 자동 탑재 가능
  * 자동화된 롤아웃과 롤백
    * 배포된 컨테이너의 원하는 상태를 서술할 수 있음 
    * 현재 상태를 원하는 상태로 변경하기 까지, 설정한 속도에 맞추어 변경할 수 있음
  * 자동화된 빈 패킹( bin packing )
    * 각 컨테이너가 필요로 하는 CPU와 메모리를 쿠버네티스에게 지시
    * 쿠버네티스는 컨테이너를 노드에 맞추어 리소스를 가장 효율적으로 사용할 수 있도록 함
  * 자동화된 복구( self-healing )
    * '사용자 정의 상태 검사'에 응답하지 않는 컨테이너를 대상으로 교체 작업을 실행
    * 클라이언트에겐 보여지지 않는 작업
  * 시크릿과 구성관리
    * 암호, OAuth, SSH 키와 같은 정보를 저장 및 관리 



* 쿠버네티스는 PaaS가 아니다!

  * Paas? 

    * Platform as a Service
    * 앱의 개발 및 시작과 관련된 인프라를 만들고 유지보수 하는 복잡함 없이 고객이 어플리케이션을 개발, 실행, 관리할 수 있게 하는 플랫폼 제공 형태
    * 서비스를 개발 할 수 있는 안정적인 환경(Platform)과 그 환경을 이용하는 응용 프로그램을 개발 할 수 있는 API까지 제공하는 형태
    * 예 :  구글 클라우드 플랫폼, 네이버 클라우드 플랫폼..

    

### 2. 쿠버네티스 컴포넌트

![쿠버네티스의 컴포넌트](https://d33wubrfki0l68.cloudfront.net/7016517375d10c702489167e704dcb99e570df85/7bb53/images/docs/components-of-kubernetes.png)



* 쿠버네티스를 배포하면 클러스터를 얻음
  * 클러스터는 컨테이너화된 애플리케이션을 실행하는, 노드라고 하는 워커 머신의 집합
  * 모든 클러스터는 최소 한 개의 워커 노드를 가짐
    * 워커 노드는 애플리케이션의 구성요소인 Pod를 호스트
  * 컨트롤 플레인은 워커 노드와 클러스터 내 Pod를 관리
    * 여러 컴퓨터에 걸쳐서 실행
  * 클러스터는 여러 노드를 실행
    * 내결함성과 고가용성 제공



* **컨트롤 플레인 컴포넌트**
  * 클러스터에 관한 전반적인 결정( 스케줄링 )을 수행
  * 클러스터 이벤트를 감지하고 반응
  * 클러스터 내 어떠한 머신에서든지 동작할 수 있음
  * **control-plane** 구성요소
    * `kube-apiserver`
      * 쿠버네티스 API 서버의 주요 구현
        * API 서버?
          * REST API 요청을 처리
          * 쿠버네티스 클러스터를 구성하는 컴포넌트들과 통신을 담당
      * 수평으로 확장하도록 디자인 됨
        * =>  더 많은 인스턴스를 배포해서 확장할 수 있음
      * 인스턴스 실행 및 트래픽 균형 조절을 담당
    * `etcd`
      * 모든 클러스터 데이터를 담음
      * 일관성, 고가용성 key-value 저장소
        * 마스터 노드의 API 서버가 HTTP/JSON API를 이용하여 접근할 수 있는 구성 데이터를 저장
      * 데이터 백업 필수
    * `kube-scheduler`
      * 노드가 배정되지 않은 새로운 Pod의 생성을 감지, 배치하여 실행할 노드를 선택
      * 스케줄링 결정 시 고려되는 요소 : 
        * 리소스에 대한 개별 및 총체적 요구사항
        * 하드웨어/소프트웨어/affinity  & anti-affinity 명세
          * affinity : Pod를 특정 Node에 배포되도록 하는 정책
        * 데이터 지역성
        * 워크로드 간 간섭
        * 데드라인
    * `kube-controller-manager`
      * 컨트롤러를 구동하는 마스터 상의 컴포넌트
      * 각 컨트롤러는 개별 프로세스
        * 단일 바이너리로 컴파일, 단일 프로세스 내에서 실행
        * 종류 :
          * 노드 컨트롤러 : 
            * 노드가 다운되었을 때 통지와 대응에 관한 책임
          * 레플리케이션 컨트롤러 : 
            * 시스템의 모든 레플리케이션 컨트롤러 오브젝트에 대해 알맞은 수의 Pod를 유지
          * 엔드 포인트 컨트롤러 : 
            * 서비스와 Pod를 연결
          * 서비스 어카운트 & 토큰 컨트롤러 : 
            * 새로운 네임스페이스에 대한 기본 계정과 API 접근 토큰을 생성
    * `cloud-controller-manager`
      * 클라우드별 컨트롤 로직을 포함하는 쿠버네티스 컨트롤 플레인 컴포넌트
      * 클러스터를 클라우드 공급자의 API에 연결
        * ( 해당 클라우드 플랫폼과 상호작용하는 컴포넌트 )와 ( 클러스터와 상호작용하는 컴포넌트 )를 분리
      * 클라우드 컨트롤러 매니저는 클라우드 제공자 전용 컨트롤러만 실행한다.
      * `kube-controller-manager`와 실행 방법 동일, 확장 방식 동일
      * 클라우드 환경과 의존성을 띄는 컨트롤러 : 
        * 노드 컨트롤러
          * 노드가 응답이 없을 때 클라우드 상에서 존재 여부를 확인
        * 라우트 컨트롤러
          * 기본 클라우드 인프라에 경로를 구성
        * 서비스 컨트롤러
          * 클라우드 환경에 맞는 로드 밸런서 생성, 업데이트, 삭제



* **Node 컴포넌트**

  * 동작 중인 Pod를 유지

  * 쿠버네티스 런타임 환경 제공

  * 모든 노드 상에서 동작하는 컴포넌트

  * **Node** 구성 요소

    * `kubelet`

      * 각 노드에서 실행되는 에이전트
      * Pod에서 컨테이너 동작을 관리
        * PodSpec의 정보를 받아 컨테이너가 스펙 정보에 맞게 동작하는지 확인
        * 오로지 쿠버네티스를 통해서 생성된 컨테이너만 관리

    * `kube-proxy`

      * 각 노드에서 실행되는 네트워크 프록시
        * 노드의 네트워크 규칙을 유지, 관리
        * 네트워크 규칙을 통해 내부 네트워크 세션이나 클러스터 외부에서 Pod로 네트워크 통신을 할 수 있도록 한다.
      * Service 구현부
        * 로드밸런서 역할
      * 트래픽 자체를 *forward*
        * 운영 체제에 가용한 패킷 필터링 계층이 있는 경우, 이를 사용

    * `컨테이너 런타임`

      * 컨테이너의 실행을 담당하는 소프트웨어

      

### 3. 쿠버네티스 API

* 쿠버네티스 control plane의 핵심
* 통신을 위한 HTTP API를 제공
* 쿠버네티스 API 오브젝트를 조작
  * Pod
  * Namespace
  * ConfigMap
  * Event



* API는 지속적으로 변경된다.
  * 기존 호환성을 유지해나가며 새로운 API를 추가, 혹은 변경하는 것을 목표로 함



* OpenAPI

  * `/openapi/v2` 엔드포인트에서만 제공

  * 다음과 같은 요청 헤더를 이용하여 응답값을 받을 수 있음

    | Header             | Possible values                                              | Notes                                          |
    | ------------------ | ------------------------------------------------------------ | ---------------------------------------------- |
    | `Accept-Encoding`  | `gzip`                                                       | *not supplying this header is also acceptable* |
    | `Accept`           | `application/com.github.proto-openapi.spec.v2@v1.0+protobuf` | *mainly for intra-cluster use*                 |
    | `application/json` | *default*                                                    |                                                |
    | `*`                | *serves* `application/json`                                  |                                                |

  * 클러스터 내부 통신용 API

    * Protobuf에 기반한 직렬화 형식으로 구현



* API 버전 규칙

  * API 버전은 명명 규칙을 따라야 하고, 이름에 따라 안정성과 기술 지원의 수준이 달라진다.

  * `알파 수준( alpha )`:

    * 버전 이름에 `alpha`가 포함 (예: `v1alpha1`)

    - 안정성이 낮고, 버그가 발생할 가능성이 있다.
    - 기본적으로 비활성화되어 있다.
    - 기능에 대한 기술 지원이 언제든 공지 없이 중단될 수 있다.
    - 다음 소프트웨어를 릴리스할 때 공지 없이 API의 호환성이 깨지는 방식으로 변경될 수 있다.
    - 버그의 위험이 높고 장기간 지원되지 않으므로 단기간 테스트 용도의 클러스터에서만 사용하기를 권장한다.

  * `베타 수준( Beta )`:

    * 버전 이름에 `beta`가 포함 (예: `v2beta3`).

    - 안정성이 보장되어 있다.
    - 기본적으로 활성화되어 있다.
    - 구체적인 내용이 바뀔 수는 있지만, 전반적인 기능에 대한 기술 지원이 중단되지 않는다.
    - 오브젝트에 대한 스키마나 문법이 다음 베타 또는 안정화 릴리스에서 호환되지 않는 방식으로 바뀔 수도 있다. 
      - API 오브젝트의 삭제, 편집 또는 재생성이 필요할 수도 있다. 
      - 이 기능에 의존하고 있는 애플리케이션은 다운타임이 필요할 수도 있다.
    - 다음 릴리스에서 호환되지 않을 수도 있으므로 사업적으로 중요하지 않은 용도로만 사용하기를 권장 

  * `안정화 수준( stable )`:

    - 버전 이름이 `vX`
      -  `X` 는 정수
    - 안정화 버전의 기능은 이후 여러 버전에 걸쳐서 소프트웨어 릴리스에 포함



* API 그룹

  * REST 경로와 직렬화된 객체의 apiVersion 필드에 명시됨

  * API를 보다 쉽게 확장하기 위함

    * 사용자 지정 리소스로 확장

      1. CustomResourceDefinition

         * Deployment, Service와 같은 쿠버네티스 오브젝트 종류를 정의하여 API를 확장, 사용

           

      2. API Aggregation

         

  * 그룹의 종류 :

    1. 레거시 그룹 ( core group )
       * REST 경로 : `/api/v1`
       * `apiVersion : v1`
    2. Named group
       * REST 경로 : `/apis/$GROUP_NAME/$VERSION`
       * `apiVersion: $GROUP_NAME/$VERSION`
    3. 이외 목록 참조 : 
       * https://kubernetes.io/ko/docs/reference/

    

* API 그룹 활성화 / 비활성화
  * kube-apiserver에서 명령어를 이용하여 활성화 / 비활성화 설정이 가능
  * `--runtime-config`
    * 쉼표로 분리된 값을 허용
    * 예 : `--runtime-config=batch/v1=false`



* 직렬화 형식의 API 리소스는 모두 ` etcd`에 기록 및 저장



### 4. 쿠버네티스 오브젝트로 작업하기

#### 4-1. 쿠버네티스 오브젝트 이해하기

* 쿠버네티스 오브젝트?

  > *하나의 "의도를 담은 레코드"*

  * 쿠버네티스 시스템에서 영속성을 가지는 개체
  * 클러스터의 상태를 나타내기 위해 이 개체를 이용
    * 예 : 
      * 어떤 컨테이너화된 애플리케이션이 동작 중인가?
      * 어떤 노드에서 동작 중 인가?
      * 어떤 리소스를 사용할 수 있는가?
  * 클러스터의 **상태**
    * 오브젝트를 통해서, 클러스터의 워크로드를 어떤 형태로 보이고자 하는지에 대해 쿠버네티스 시스템에 전달
    * => 클러스터에 대해 **의도한 상태**
  * 쿠버네티스 오브젝트 동작
    * 쿠버네티스 API 이용



* 오브젝트의 Spec( 명세 )와 상태( Status )
  * 오브젝트의 구성을 결정하는 필드
  * `spec`
    * 오브젝트를 생성할 때, 리소스에 원하는 특징에 대한 설명을 제공해서 설정
  * `status`
    *  쿠버네티스 시스템과 컴포넌트에 의해 제공
    * 동작하는 애플리케이션을 표현해줄 수 있는 오브젝트
  * 예시 : 
    * deployment 생성 시, `spec` 필드를 이용하여 ReplicaSet 갯수 설정 가능
      * 쿠버네티스는 spec을 읽은 뒤, 이와 일치 되도록 상태를 업데이트
      * 의도한 갯수의 애플리케이션 인스턴스를 구동한다.
    * 구동한 인스턴스에 문제가 발생하면, 
      * spec과 status 간의 차이를 비교하여 문제에 대응한다. 



* 오브젝트 작성

  * 오브젝트 생성 시, name과 같은 기본정보 뿐만 아니라, 관리자가 원하는 상태를 기술한 오브젝트의 spec을 함께 제시하여햐 한다.

  * 오브젝트 생성을 위해 쿠버네티스 API를 이용할 때, 

    * 요청 내용 안에 JSON 형식으로 정보를 포함해야 함
    * .yaml 파일로 kubectl에 제공, => kubectl이 API 요청을 받고 JSON 형식으로 정보 변환

  * ```yaml
    apiVersion: apps/v1 # for versions before 1.9.0 use apps/v1beta2
    kind: Deployment
    metadata:
      name: nginx-deployment
    spec:
      selector:
        matchLabels:
          app: nginx
      replicas: 2 # tells deployment to run 2 pods matching the template
      template:
        metadata:
          labels:
            app: nginx
        spec:
          containers:
          - name: nginx
            image: nginx:1.14.2
            ports:
            - containerPort: 80
    ```



#### 4-2. 쿠버네티스 오브젝트 관리

> `kubectl`  커맨드 라인 툴을 이용하여 오브젝트를 생성, 관리한다. 



* 대표적인 기법 3가지

  | 관리기법             | 대상                 | 권장 환경     | 지원하는 작업자 수 | 학습 난이도 |
  | -------------------- | -------------------- | ------------- | ------------------ | ----------- |
  | 명령형 커맨드        | 활성 오브젝트        | 개발 환경     | 1+                 | 낮음        |
  | 명령형 오브젝트 구성 | 개별 파일            | 프로덕션 환경 | 1                  | 보통        |
  | 선언형 오브젝트 구성 | 파일이 있는 디렉터리 | 프로덕션 환경 | 1+                 | 높음        |

  1. 명령형 커맨드

     * 특징 :
       * 클러스터 내 활성 객체를 대상으로 직접 동작
       * 클러스터에서 일회성 작업을 동작시키기 위한 가장 단순한 방법
       * 활성 객체에게 직접적으로 영향을 미친다.

     * 예시 : 

       * deployment 객체를 생성하여 nginx 컨테이너의 인스턴스를 구동

         ```
         kubectl create deployment nginx --image nginx
         ```

     * 장점 : 

       * 간단하고 쉬운 커맨드 입력 방식
       * 단 한번의 동작으로 클러스터를 변경할 수 있음

     * 단점 :

       * 변경 내역에 대해, 변경 검토 프로세스와 통합되지도 않고, 변경 내역을(audit trail) 제공하지도 않음
       * 활성화된 노드에 대해서만 레코드 소스를 제공한다.
       * 새로운 객체 생성에 대해 템플릿을 제공하지 않는다.

  2. 명령형 객체 구성

     * 특징 :

       *  YAML 또는 JSON 형식의 파일과 , kubectl 명령어를 이용하여 객체를 구성 및 생성한다.
         * 파일에서는 객체 구성에 필요한 부분이 모두 포함되어 있어야 한다!

     * 예시 :

       * ```
         # 구성 파일에 정의된 객체를 생성
         kubectl create -f nginx.yaml
         
         # 객체 삭제
         kubectl delete -f nginx.yaml -f redis.yaml
         
         # 덮어쓰기
         kubectl replace -f nginx.yaml
         ```

     * 장점 : 

       * 객체 구성 내용이 파일로 이루어져있기 때문에, Git 과 같은 소스 컨트롤 시스템에 보관할 수 있음
       * 변경사항을 추적하는 프로세스들과 통합할 수 있다
         * 변경 내역을 볼 수 있다는 뜻
       * 파일 형태의 객체 생성 템플릿을 제공

     * 단점 : 

       * 생성하려는 객체의 스키마에 대해 이해하고 있어야 한다.
       * YAML 문법을 추가적으로 이해해야한다.

  3. 선언형 객체 구성

     * 특징 : 

       * 앞선 명령형 관리 방법들과 다르게, `kubectl apply ~`명령어를 사용

         * apply 명령어는 각 객체에 대한 구성 내용을 포함하는 annotation을 설정

         * 예 : `kubectl.kubernetes.io/last-applied-configuration: '{...}'`

         * apply 명령어 작동 순서

           1. `last-applied-configuration` 항목으로부터 값을 읽어 구성 파일의 값과 비교한 뒤, 삭제할 필드를 계산한다. 

              `last-applied-configuration` 값과  무관하게 로컬의 오브젝트 구성 파일 내 null이라고 명시적으로 설정된 필드를 지운다.

           2. 구성 파일로부터 값을 읽어 활성 객체의 값과 비교하여 설정할 필드를 계산한다. 

           3. 구성 파일의 값과 일치시키기 위해 `last-applied-configuration` 어노테이션을 설정한다.

           4. 1, 2, 3으로부터의 결과를 API 서버에 단일 패치 요청으로 병합한다.

       * 파일이 아닌, 디렉토리를 대상으로 명령어를 실행한다.

       * YAML 파일에 적혀있지 않은 부분이 업데이트 되면, 그 업데이트 내용은 쭉 유지된다.

     * 예시 : 

       * ```
         # 디렉터리에 포함된 YAML 정의 파일로 객체 생성
         kubectl apply -f <디렉터리>/
         
         # 변경 후 변경 내역에 대해 체크
         kubectl diff -f <디렉터리>/
         
         # 활성화된 객체에 대한 정보를 출력
         # YAML 파일에 적힌 내용이 annotation 형태로 작성되있는 것을 확인할 수 있음
         원형 : kubectl get -f <파일명|url> -o yaml
         예시 : kubectl get deployment nginx-deployment -o yaml
         
         # 객체 삭제
         kubectl delete -f <파일명>
         ```

     * 장점 : 

       * 활성 객체에 대해 변경한 사항이 파일에 적혀있거나 파일 내용을 변경하지 않아도 유지가 된다.

     * 단점 :

       * 디렉토리를 대상으로 명령어를 실행하기 때문에, 디버깅이 어렵고 이해하기 힘들 수 있다.
       * diff 명령어를 사용한 부분 업데이트는 복잡한 병합과 패치 작업을 일으킨다.



#### 4-3. 오브젝트 이름과 ID

> 모든 쿠버네티스 객체는 전체 클러스터에 걸쳐 고유한 **UID**를 가진다.
>
> *  UID란?
>   * 객체의 중복을 막기 위해 각 객체에 붙여지는 문자열

* 이름

  * 리소스 URL에서 객체를 가리키는 클라이언트 제공 문자열

  * 하나의 이름은 하나의 객체에게

  * 리소스에 일반적으로 사용되는 세 가지 유형의 이름 제한 조건

    1. DNS 서브도메인 이름

       * RFC 1123에 정의되어 있음
       * 253자 글자 수 제한
       * 소문자, 영숫자, `-`, `.` 포함
       * 영숫자로 시작하고 끝나야함

    2. DNS 레이블 이름

       * RFC 1123
       * 63자 글자 수 제산
       * 소문자, 영숫자, `-`, `.` 포함
       * 영숫자로 시작하고 끝나야함

    3. 경로 세그먼트 이름

       * 몇몇 경로 세그먼트는 인코딩 안정성을 위해 이름에 제약을 붙일 수 도 있다.

         

#### 4-4. 네임스페이스

> 동일한 물리 클러스터 내에서는 네임스페이스를 이용하여 클러스터 자원을 나눈다.
>
> 동일한 네임스페이스 내에서는 **레이블**을 이용하여 리소스를 구별한다.



* 네임스페이스 활용법

  ```
  # 생성된 네임스페이스 조회
  kubectl get namespaces
  
  # 네임스페이스에 속하는 리소스
  kubectl api-resources --namespaced=true
  
  # 네임스페이스에 속하지 않는 리소스
  kubectl api-resources --namespaced=false
  
  # 네임스페이스 개별 설정
  # --namespace 옵션 이용
  kubectl run nginx --image=nginx --namespace=<insert-namespace-name-here>
  ```



* 서비스 생성 시 DNS 엔트리가 함께 생성되어 다음과 같은 형태를 띄게 된다:

   `<서비스-이름>.<네임스페이스-이름>.svc.cluster.local`

  * 컨테이너 설정 시 서비스만 지정하여 넘겨줄 경우, 네임스페이스는 자동으로 서비스와 연결된 네임스페이스가 할당된다.



* 쿠버네티스 리소스는 네임스페이스에 속한다.
  * Pod, service, replication controller
* 저수준 리소스와 네임스페이스 자체는 네임스페이스에 속하지 않는다.
  * node, persistent volume, namespace



#### 4-5. 레이블과 셀렉터

> * Pod와 같은 객체에 첨부된 key:value 쌍
>   * key값은 고유한 값
>
> * 용도
>   * 객체의 특성을 식별
>   * UI와 CLI에서 효율적인 쿼리를 사용, 검색에 사용하기 적합
>
> * 식별되지 않는 정보는 annotation으로 기록해야함



* 레이블 이용 장점
  * 조직 구조와 시스템 객체를 느슨한 결합 방식으로 매핑할 수 있음
  * 매핑 정보를 클라이언트에 저장할 필요가 없음



* 레이블 사용 예시
  * `"release" : "stable"`, `"release" : "canary"`
  * `"environment" : "dev"`, `"environment" : "qa"`, `"environment" : "production"`
  * `"tier" : "frontend"`, `"tier" : "backend"`, `"tier" : "cache"`
  * `"partition" : "customerA"`, `"partition" : "customerB"`
  * `"track" : "daily"`, `"track" : "weekly"`



* 레이블 네이밍 규칙

  * 2개의 세그먼트 존재

    * 접두사 - 이름
    * 접두사
      * 선택사항
      * 슬래시('/')로 구분된다.
      *  DNS 하위 도메인 값이어야 함
        * 253자 이하, 점('.')과 슬래시('/')로 구분되는 DNS 레이블
      * `kubernetes.io/`와 `k8s.io/` 접두사는 쿠버네티스의 핵심 컴포넌트로 예약
    * 이름
      * 63자 미만
      * 알파벳과 숫자로 시작과 끝
      * 대시(`-`), 밑줄(`_`), 점(`.`) 사용 가능

  * 작성 예시 : 

    ```yaml
    apiVersion: v1
    kind: Pod
    metadata:
      name: label-demo
      labels:
        environment: production
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.14.2
        ports:
        - containerPort: 80
    
    # 2개의 레이블 존재
    # environment: production
    # app: nginx
    ```





* **레이블 셀렉터**

  * 고유하지 않은 레이블 값을 어떻게 구분할 수 있을까?

  * => 레이블 셀렉터를 이용하여 클라이언트와 사용자는 레이블을 식별할 수 있음

  * API가 지원하는 셀렉터

    1.  *equality-based*

       * 일치 - 불일치의 기준을 요구사항으로 레이블의 키-값 필터링

       * 요구사항과 일치하는 객체는 추가 레이블을 가질 수 있으나, 해당 레이블에 걸린 조건을 모두 만족해야함

       *  `=`,`==`,`!=` 이 3가지 연산자만 허용

       * 일치 :  `=`,`==`

       * 불일치 : `!=`

       * 이용 예시 : 

         * Pod가 셀렉터를 이용하여 Node를 선택하는 기준을 지정

         * ```yaml
           apiVersion: v1
           kind: Pod
           metadata:
             name: cuda-test
           spec:
             containers:
               - name: cuda-test
                 image: "k8s.gcr.io/cuda-vector-add:v0.1"
                 resources:
                   limits:
                     nvidia.com/gpu: 1
             nodeSelector:
               accelerator: nvidia-tesla-p100
               
           # 이 Pod는 nodeselector의 값에 해당하는 node를 선택하게 된다.
           ```

    2. *set-based*

       * 집합을 이용하여 키값을 필터링

       *  `in`,`notin` and `exists`(키 식별자만 해당)의 3개의 연산자를 지원

       * 예시 : 

         ```
         environment in (production, qa)
         # 키가 environment인 리소스 중에 값이 production이거나 qa인 리소스를 선택
         
         tier notin (frontend, backend)
         # tier 중에 frontend와 backend가 아닌 리소스를 선택
         
         partition
         # partition 키 값을 포함하는 모든 리소스
         
         !partition
         # partition 키 값을 포함하지 않는 모든 리소스
         ```

         

  

  * 셀렉터는 쉼표로 구분
  * 다양한 요구사항에 따라 생성 가능
    * 쉼표 기호를 AND(&&) 연산자로 구분할 수 있어야함

  

* API를 이용한 레이블 쿼리

  * REST 클라이언트를 통해 선택된 리소스를 확인

    * LIST와 WATCH

  * 예시 : 

    * ```
      kubectl get pods -l environment=production,tier=frontend
      
      kubectl get pods -l 'environment in (production),tier in (frontend)'
      ```

      

#### 4-6. 어노테이션

> annotation을 이용하여 비 식별 메타데이터를 객체에 첨부한다.
>
> 해당 메타 데이터는 검색 가능



* 특징 : 

  * 객체 식별 및 선택에 사용하는 값은 아니다!

  * 레이블과 같이 키-값 으로 매핑

    * ```yaml
      "metadata": {
        "annotations": {
          "key1" : "value1",
          "key2" : "value2"
        }
      }
      ```

    * annotation으로 기록할 수 있는 정보의 예시 : 

      * 필드
        * 선언적 구성 계층에 의해 관리
        * 클라이언트 또는 서버가 설정한 기본 값, 자동 생성된 필드, 그리고 오토사이징 또는 오토스케일링 시스템에 의해 설정된 필드와 구분.
      * 빌드, 릴리스, 또는 타임 스탬프, 릴리즈 ID, git 브랜치, PR 번호, 이미지 해시 및 레지스트리 주소와 같은 이미지 정보.
      * 로깅, 모니터링, 분석 또는 감사 리포지터리에 대한 포인터.
      * 디버깅 목적으로 사용될 수 있는 클라이언트 라이브러리 또는 도구 정보: 
        * 예를 들면, 이름, 버전, 그리고 빌드 정보.
      * 다른 생태계 구성 요소의 관련 오브젝트 URL과 같은 사용자 또는 도구/시스템 출처 정보.
      * 경량 롤아웃 도구 메타데이터
        *  예: 구성 또는 체크포인트
      * 책임자의 전화번호 또는 호출기 번호, 또는 팀 웹 사이트 같은 해당 정보를 찾을 수 있는 디렉터리 진입점.
      * 행동을 수정하거나 비표준 기능을 수행하기 위한 최종 사용자의 지시 사항.



* annotation 네이밍 규칙 :

  * 앞서 언급된 레이블과 네이밍 규칙이 거의 동일하다.

  

#### 4-7. 필드 셀렉터

> 한 개 이상의 리소스 필드 값에 따른 쿠버네티스 리소스 선택을 위해 사용된다.



* 사용 예시 : 

  * ```
    kubectl get pods --field-selector status.phase=Running
    ```

  * 사용할 수 없는 셀렉터를 쿼리에 사용하면 에러 출력

  * 사용 가능 연산자 : 

    *  `=`, `==`, `!=` 

  * 연계 셀렉터

    * ```
      kubectl get pods --field-selector=status.phase!=Running,spec.restartPolicy=Always
      ```

    * 쉼표로 목록을 구분하여 필드 셀렉터를 연계해서 사용할 수 있다.

  



## 2. 클러스터 아키텍쳐

### 1. 노드

> 클러스터에 따라 가상, 또는 물리적 머신으로 구성
>
> 각 노드에는 control plane이라는 Pod를 실행하는 데 필요한 서비스가 포함되어 있다.
>
> * 노드 구성요소
>   * `kubelet`, `container runtime`, `kube-proxy`



* API 서버에 노드를 추가하는 방법
  1. 노드의 `kubelet`으로 control plane 자체에 등록
     * kubelet의 `--register-node=true` 옵션이 있을 경우, API 서버에 자동으로 등록된다.
     * 대체로 배포를 위해 이용된다.
  2. 사용자가 노드 객체를 수동으로 추가
     *  `--register-node=false` 일 경우, 노드를 수동으로 생성해야 한다.
     * 수정은 `--register-node` 값과 관련없이 개별적으로 수정이 가능하다.



* `kubectl cordon $NODENAME`

  * 노드에게 스케줄 불가 옵션 부여

  * 스케줄러가 해당 노드에 새 파드를 배치할 수 없게 된다.

    * 기존 파드에는 영향 미치지 않는다.
    * 노드 재부팅, 기타 유지보수 단계에서 유용한 옵션

    ※ DaemonSet에 포함되는 일부 Pod는 스케줄 불가 옵션의 노드에서도 실행 될 수 있다..~!

    *  이유 : 데몬셋에서는 워크로드 애플리케이션이 중단된 노드에서도 Pod가 실행되도록 하는 node-local 서비스를 제공하기 때문!



* 노드의 상태

  * 확인 방법 : 
  * `kubectl describe node <insert-node-name-here>`

  1. 주소
     * 주소는 쿠버네티스에 결합된 클라우드 환경이나, 베어메탈 구성에 따라 달라질 수 있다.
     * 주로 다음과 같은 항목을 가진다.
       * HostName: 노드의 커널에 의해 알려진 호스트명이다. `--hostname-override` 파라미터를 통해 치환될 수 있다.
       * ExternalIP: 일반적으로 노드의 IP 주소는 외부로 라우트 가능 (클러스터 외부에서 이용 가능) 하다 .
       * InternalIP: 일반적으로 노드의 IP 주소는 클러스터 내에서만 라우트 가능하다.
  2. 컨디션
     * 활성화, 즉 `running` 중인 노드의 모~ 든 상태를 표시한다.
     * 표시되는 상태에 대한 예시
       * Ready :
         * `True` : 노드 상태가 양호, Pod를 수용할 준비가 되었다!
         * `False` : 노드 상태 불량, Pod를 받을 준비가 안되었다!
         * `Unknown` :  노드 컨트롤러가 해당 노드로부터 기본값( 40 ) 내에 아직 응답값을 받지 못해서 아무것도 모르겠다!
       * DiskPressure :
         * `True` : 디스크 용량 부족..
         * `False` : 디스크 용량 부족하진 않다.
       * MemoryPressure : 
         * `True` : 메모리 용량 부족..
         * `False` : 메모리 용량 부족하진 않다.
       * PIDPressure : 
         * `True` : 노드에서 실행 중인 프로세스가 너무 많다..
         * `False` : 노드에서 실행 중인 프로세스 갯수 많지 않다.
       * NetworkUnavailable :
         * `True` : 노드의 네트워크 구성이 올바르지 않다.
         * `False` : 노드의 네트워크 구성 잘되었다.
     * `taints`  테인트 : 
       * 자동으로 노드의 컨티션을 나타내는 것.
       * 스케줄러가 Pod를 노드에 할당하려 할 때, 해당 노드의 taint를 참고한다.
       * `Unknown`이나 `False` 상태가 기본 축출 타임아웃 시간( 5분 )보다 더 길게 유지되면, 노드 상의 모든 Pod는 삭제하도록 스케줄링된다.
         * 다만, 삭제되도록 스케줄링될 뿐이지, apiserver와 통신이 되지 않으면 삭제 처리가 kubelet에 전달되지 못해서 삭제 명령이 곧바로 이루어지지 않을 수 있다
         * => 삭제되야하는 Pod가 축출 시간 이후에도 동작하고 있을 수도 있다는 말!!
         * 이럴 때는 아예 노드 객체를 삭제해버리면 된다. 
  3. 전체 용량 && 할당 가능한 용량
     * 노드 상에 사용 가능한 리소스를 표현
     * CPU, 메모리, 노드 상에서 최대로 스케줄 될 수 있는 Pod의 수
     * capacity : 
       * 노드에 있는 리소스 총량
     * allocatable : 
       * 일반 Pod에서 사용할 수 있는 노드의 리소스 양
  4. 노드의 정보
     * Kubelet에 의해 수집되는 정보
     * 노드의 커널 버전, 쿠버네티스 버전, Docker 버전, OS 이름 등등,,



* Node Controller
  * 노드의 다양한 측면을 관리하는 쿠버네티스 control plane 구성요소.
  * 노드의 생성부터 유지까지!
    1. 생성될 때, 노드에 CIDR 블럭 할당
    2. 컨트롤러 내 노드 리스트를 항상 최신으로 업데이트
       * 연결된 클라우드 환경으로부터 노드의 상태를 받아 업데이트
       * 불량한 노드는 사용 가능성 여부에 따라 삭제된다.
    3. 노드의 동작 상태 모니터링
       * 노드가 접근 불가능한 경우 ( 예 : 노드 다운 ) 노드의 상태를 확인하고 Pod를 축출할 때까지의 과정
       * ConditioinUnknown이 되는 기본 타임아웃 값 :  40초
       * Pod 축출하기 시작하는 기본 타임아웃 값 :  5분
       * `--node-monitor-period` 로 매 초마다 각 노드의 상태 체크



* HeartBeat
  * 노드의 가용성을 결정하는데 도움을 준다.
  * 2가지의 형태
    1. NodeStatus
    2. Lease 객체
       * `kube-node-lease`
       * 각 노드에 있는, 네임스페이스와 관련된 객체
       * 경량 리소스
       * 클러스터가 확장될 때, 노드의 하트비트 성능을 향상
  * `kubelet`에 의해 업데이트
    * NodeStatus의 업데이트 주기 : 5분
    * Lease 객체 : 10초마다 객세 생성 및 업데이트
      * NodeStatus와 독립적으로 업데이트
      * 실패 시 kubelet이 재시도
        * 7초로 제한된 지수 백오프를 200밀리초에서부터 시작 (?)



* 안정성
  * 노드 축출
    * 대부분의 경우, 초당 노드 축출 비율은 제한되어 있음
      * 10초당 1개의 노드를 초과하여 없애지 않는다!
    * 노드 컨트롤러가 담당하는 영역 내의 불량한 노드의 비율에 따라 축출 비율이 변화한다. 
    * *코너 케이스*
      * 하나의 영역 내 모든 노드들이 상태가 불량할 때 발생
      * 컨트롤러는 마스터 연결에 문제가 있다고 판단하고, 연결이 복원될 때까지 모든 축출을 중지한다.
    * `NoExecute` taint 상태
      * 컨트롤러는 이 상태에 해당하는 노드에서 동작하는 Pod에 대해 축출 책임을 가짐
      * 문제가 되는 상태에 있는 노드에 문제상황에 맞는 taint를 추가, 스케줄러가 Pod를 배치하지 않도록 한다.

* 노드 용량

  * 노드 객체는 리소스 용량에 대한 정보를 추적

  * 자동으로 노드가 생성될 때는 , 생성되면서 용량이 함께 출력된다.

  * 수동으로 노드를 추가할 때는, 노드의 용량 정보를 설정해야 한다.

  * *스케줄러의 역할*

    * 모든 노드에게 충분한 리소스가 존재하도록 보장

    * 노드 상에서 실행되는 컨테이너들이 보내는 리소스에 대한 요청의 합이 노드가 가진 리소스 용량보다 크지 않도록 체크

      * 요청의 합?
        * kubelet에서 관리하는 모든 컨테이너 포함
        * 컨테이너 런타임에 의해 직접적으로 시작된 컨테이너는 제외
        * kubelet 컨트롤 범위 밖의 프로세스도 제외

    * Pod가 아닌 프로세스 단위로 리소스 확보를 위해서는?

      * 시스템 테몬에 사용할 리소스 예약하기 참고
      * https://kubernetes.io/docs/tasks/administer-cluster/reserve-compute-resources/#system-reserved

      



### 2. 컨트롤 플레인-노드 간 통신



* 노드 => control plane( API server ) 간의 통신
  * 쿠버네티스의 API 패턴 : hub and spoke pattern
    * 노드의 모든 API 사용은 API 서버에서 종료
    * 하나 이상의 클라이언트 인증 형식이 활성화된 보안 HTTPS 포트( default : 443 )에서 원격 연결을 수신하도록 구성
      * control plane은 보안 포트를 이용해서 클러스터 API와도 소통
    * Pod는 어떻게 안전하게 API 서버에 연결할 수 있을까?
      * 서비스 어카운트를 활용!
      * Pod가 서비스 어카운트를 활용하면, Pod가 인스턴스화 될 때, 쿠버네티스는 자동적으로 퍼블릭 루트 증명서와 유효한 베어러 토큰( bearer token )을 주입



* control plane( API server ) => 노드 간의 통신

  * 두 가지의 기본 통신 경로

    1. API 서버에서 =>  kubelet 

       * 통신 용도

         * 파드에 대한 로그를 가져온다.
         * 실행 중인 파드에 (kubectl을 통해) 연결한다.
         * kubelet의 포트-포워딩 기능을 제공한다.

       * 신뢰할 수 없는 네트워크 & 공용 네트워크에서의 안정성 :  *낮음*

         * 이유 : API 서버는 기본적으로 kubelet의 serving certificate을 확인하지 않는다.

         * 대안 :

           1.  `--kubelet-certificate-authority`플래스 사용
              * API 서버가 kubelet의 serving certificate을 확인할 수 있도록 루트 인증서 번들을 제공

           2. API 서버와 kubelet 사이에 SSH 터널링 사용
           3. kubelet 인증/ 권한 부여 옵션을 활성화

    2. API 서버의 프록시 기능을 통해 => 모든 노드, Pod, 서비스

       * 기본적으로 일반 HTTP 연결이 되어 보안상 안전하지 않음
       * HTTPS 연결이 가능하긴 하지만, 보안 연결을 한다고 해서 HTTPS 엔드포인트의 인증서를 검증하지는 않음

    

* SSH 터널 
  
  * 더이상 사용되지 않으며, *Konnectivity 서비스*가 대체
* Konnectivity 서비스
  * Control plane와 클러스터 간의 통신에서 TCP 레벨의 프록시를 제공
  * 두 부분으로 구성
    1. Konnectivity 서버 ( control plane 네트워크에서 작동 )
    2. Konnectivity 에이전트 ( 노드 네트워크에서 작동 )
       * konnectivity 서버에 대한 연결을 시작, 네트워크 연결을 유지
  * konnectivity 서비스를 활성화하면, 모든 Control plane에서 노드로의 트래픽은 이 연결을 통과



### 3. 컨트롤러

> 컨트롤 루프 
>
> * 시스템 상태를 조절하는 종료되지 않는 루프
>   * 예 : 실내 온도 조절기
>   * 사용자가 의도한 상태 ( 원하는 온도 )로 조절하면 온도 조절기가 사용자가 원하는 상태로 온도를 조절



* 컨트롤러 패턴

  * 컨트롤러는 적어도 하나 이상의 쿠버네티스 리소스를 추적한다.

    * 리소스에는 관리자가 의도한 상태를 나타내는 사양 필드가 포함되어있고, 컨트롤러는 이러한 사양을 보고 객체를 사양에 가깝게 만든다.

  * 컨트롤러 제어 방법

    1. API 서버를 통한 제어

       * Job 컨트롤러

         * 쿠버네티스 내장 컨트롤러

         * 클러스터 API 서버와 상호작용하며 상태를 관리한다.

           * Pod나 컨테이너를 직접 실행하지 않고, API 서버에게 지시하는 방식

         * Job이란?

           * 하나 이상의 Pod를 실행한 뒤, 작업을 수행하고 중지하는 쿠버네티스 리소스

         * 작동 순서

           1. Job 컨트롤러가 새로운 작업을 확인

           2. 클러스터 노드 내의 kubelet이 작업을 수행하기에 적합한 숫자의 Pod를 실행

              * 새 Job이 생성되면, *완료*가 목표가 된다.
              * 완료된 객체를 대상으로 컨트롤러는 객체의 설정을 업데이트
                * 예 : 완료된 Job : `Finished`

              

    2. 직접 제어

       * 클러스터 외부의 것을 변경하기 위한 컨트롤러
       * 외부 상태와 상호작용
         * API 서버에서 의도하는 상태를 찾고, 외부 시스템과 통신해서 현재 상태를 변경한다.
         * 예 : 클러스터 오토 스케일링



* Desired State & Current State
  * 클라우드 네이티브 관점에서 시스템을 관찰,
  * Job이 발생함에 따라 클러스터가 변경되고, 실패 시 컨트롤 루프가 바로잡는다.
  * 컨트롤러가 잘 작동하는 한, 쿠버네티스의 유동적인 상태는 문제가 되지 않는다.
    * 어차피 컨트롤러가 계속 바로잡을 것이기 때문에...



* 디자인
  * 컨트롤 루프로 구성된 모놀리식 집합이 아닌, 간단한 컨트롤러 여러개를 복합적으로 구동
  * 예 : Job을 실행할 때
    *  Job을 수행할 Pod는 Job 컨트롤러가 생성
    * Pod가 수행할 Job은 다른 컨트롤러가 생성
  * 여러개의 컨트롤러가 있으므로, 각 컨트롤러 간에 관리하는 객체의 종류가 겹칠 수 있음
    * 따라서 각 컨트롤러는 자신과 중복되는 종류의 객체를 자신이 관리하는 객체와 **레이블**로 객체를 구분



* 컨트롤러 실행 방법

  * 대표적인 쿠버네티스 자체( 내장 ) 컨트롤러
    * Deployment 컨트롤러
    * Job 컨트롤러
    * 컨트롤러는 실패하더라도 다른 control plane의 일부가 작업을 이어 수행할 수 있다.

  



### 4. 클라우드 컨트롤러 매니저





## 3. 컨테이너



## 4. 워크로드



## 5. 서비스, 로드밸런싱, 네트워킹



## 6. 스토리지



## 7. 구성



## 8. 보안



## 9. 스케줄링과 축출(eviction)



## 10. Policy



## 11. 클러스터 관리





## 12. 쿠버네티스 확장



허